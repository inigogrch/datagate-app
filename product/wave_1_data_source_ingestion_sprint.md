### GitHub Issue â€” "Wave 1 Dataâ€‘Source Ingestion Sprint"

**Title**\
`feat(ingestion): add Wave 1 adapters (AWS Big Data, OpenAI, Excel/Power BI, PyPI, Google AI, HF Models, arXiv, MIT Tech Review, TLDR, TechCrunch, MIT Sloan, VentureBeat, Ars Technica)`

---

#### Background

We've finalised the content taxonomy and the canonical `ParsedItem` DTO. The next milestone is to light up the first batch of external feeds so the dashboard isn't limited to dbt blog content.

---

#### Scope (13 adapters)

| Source                                       | Endpoint type    | Adapter stub                          | Fetch cadence |
| -------------------------------------------- | ---------------- | ------------------------------------- | ------------- |
| AWS Big Data Blog                            | RSS              | `rssAdapter('awsBigData')`            | 60 min        |
| OpenAI Official Blog                         | RSS              | `rssAdapter('openai')`                | 60 min        |
| Microsoft Excel & Power BI Blog              | RSS              | `rssAdapter('m365Excel')`             | 120 min       |
| PyPI Topâ€‘Package releases (pandas, numpy, â€¦) | JSON API         | `pypiAdapter()`                       | 180 min       |
| Google AI Research Blog                      | Web Scrape       | `rssAdapter('googleAI')`              | 60 min        |
| Hugging Face Model Releases                  | Web Scrape       | `huggingfaceAdapter()`                | 30 min        |
| arXiv (cs.AI, cs.LG, cs.CL, stat.ML)         | RSS              | `arxivAdapter(['cs.AI', â€¦])`          | 1440 min      |
| MIT Technology Review â€“ *The Download*       | RSS              | `rssAdapter('mitTR')`                 | 720 min       |
| TLDR.tech                                    | RSS (Substack)   | `rssAdapter('tldr')`                  | 720 min       |
| TechCrunch                                   | RSS              | *exists* (`rssAdapter('techcrunch')`) | 30 min        |
| MIT Sloan Management Review                  | RSS              | `rssAdapter('mitSloan')`              | 1440 min      |
| VentureBeat                                  | RSS              | `rssAdapter('ventureBeat')`           | 60 min        |
| Ars Technica                                 | RSS              | `rssAdapter('arsTechnica')`           | 60 min        |

---

#### Definition of Done

- **Source rows** inserted into `sources` table with accurate `fetch_freq_min`.
- **13 new adapter modules** exporting `fetchAndParse(): ParsedItem[]`.
- **Unit tests** (Jest) for each adapter using fixture payloads (happy path + 1 edgeâ€‘case).
- **dbt schema tests** green (no NULL `stories.published_at`, vector present, etc.).
- **Grafana dashboard** panels autoâ€‘generated for each adapter (last success, error %).
- **p95 ETL latency** for Wave 1 feeds < 10 min.
- **Supabase row count** checked postâ€‘backfill (< 8 k rows, staying within 100 k cap).
- **Flexible tagging** system replacing hardcoded categories for dynamic content classification.

---

#### Tech Notes

- RSS adapters reuse `rssParser.ts` util (xml2js â†’ DTO).
- `pypiAdapter()` loops through `TOP_PACKAGES` env var array; deâ€‘dupes by `externalId = '${pkg}@${version}'`.
- arXiv: build categoryâ€‘parametrised URL, strip LaTeX from `<summary>`.
- **All adapters** strip zeroâ€‘width chars & convert HTMLâ†’Markdown via `turndown`.
- Batch embed with `textâ€‘embeddingâ€‘3â€‘small`; hashâ€‘gate unchanged bodies.

---

#### Impact

Populates the system with â‰ˆ1000+ fresh stories from diverse sources, each intelligently tagged for flexible categorization. This unlocks endâ€‘toâ€‘end UX tests, semantic search capabilities, and the relevanceâ€‘feedback loop before GA.

---

#### Reviewer Checklist

- Coding style & lint pass (`pnpm lint`).
- Unit tests cover failure modes (404, malformed XML).
- Manual run `pnpm run ingest --source=openai` ingests â‰¥ 1 item, visible in dashboard.
- Grafana alert thresholds set (error % > 5 %, latency > 5 min).

---

#### Dependencies

- \#42 "Supabase vector index tuning" (merged)
- \#55 "Grafana datasource for Logflare logs" (in review)

---

### 2 Â· Implementation Plan (ðŸ‘‹ Cursorâ€‘first workflow)

| Phase                      | Cursor instruction                                                                                                           | CLI / Code tasks                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |
| **0 Prep**                 | "Generate a `wave1â€‘ingestion` branch from `main`."                                                                           | `git checkout -b wave1-ingestion`                   |
| **1 Source Inserts**       | "Create a SQL migration inserting 12 rows into `sources` with (name, type, endpoint\_url, fetch\_freq\_min, row\_category)." | `supabase migrate new add_wave1_sources` â†’ edit SQL |
| **2 Adapter Stubs**        | "Scaffold TypeScript modules in `packages/adapters/` for each feed, exporting `fetchAndParse()`."                            | Cursor autoâ€‘creates 12 files                        |
| **3 Parsing Logic**        | "Implement `rssAdapter` generic wrapper; call with feedâ€‘specific slug."                                                      | Add slugâ†’sourceId util                              |
| **4 PyPI Adapter**         | "Loop over `PYPI_TOP_PACKAGES` env var â†’ fetch `https://pypi.org/p/<pkg>/json` â†’ map releases."                              | Cache lastâ€‘seen version in KV                       |
| **5 HF / arXiv**           | "Use `axios` to hit APIs; map JSONâ†’DTO; sanitize abstracts."                                                                 | Add `removeLatex.ts` helper                         |
| **6 Tests**                | "Generate Jest skeletons per adapter with fixture XML/JSON in `tests/fixtures/`."                                            | Add edgeâ€‘case fixture                               |
| **7 Cron Wireâ€‘up**         | "Update `ingestCron.ts` switchâ€‘case with new slugs."                                                                         | Keep concurrency â‰¤ 4                                |
| **8 Observability**        | "Extend `metrics.ts` to emit `adapter_latency_ms` & `adapter_error`."                                                        | Grafana regex panels                                |
| **9 Dry Run**              | "Run `pnpm ts-node src/cli/ingest --source=all --dry-run` and show summary."                                                 | Validate DTO & row diff                             |
| **10 Backfill**            | "Disable `DRY_RUN`, execute ingestion once, check feed UI."                                                                  | Ensure vector count < 100 k                         |
| **11 PR & Review**         | "Open PR titled **feat: Wave 1 adapters**; autoâ€‘generate changelog section."                                                 | Assign reviewers                                    |
| **12 Rollout**             | "Merge â†’ GitHub Actions deploy â†’ Vercel staging â†’ promote to prod after 24 h green metrics."                                 | Monitor alerts                                      |

> **Cursor tip:** prefix each instruction with `@cursor` so Cursor queues the task automatically:
>
> ```ts
> // @cursor TASK: Implement rssAdapter('openai')
> ```

With this issue and plan in place, Wave 1 ingestion can be delivered in a single sprint, bringing real multiâ€‘source content to beta testers.

