### GitHub Issue â€” â€œWaveâ€¯1 Dataâ€‘Source Ingestion Sprintâ€

**Title**\
`feat(ingestion): add WaveÂ 1 adapters (AWSÂ BigÂ Data, OpenAI, Excel/PowerÂ BI, PyPI, GoogleÂ AI, HFÂ Models, arXiv, MITÂ TechÂ Review, NeurIPS, TLDR, TechCrunch, HBRÂ Tech, insideAI)`

---

#### Background

Weâ€™ve finalised the 3â€‘row content taxonomy and the canonical `ParsedItem` DTO. The next milestone is to light up the first batch of external feeds so the dashboard isnâ€™t limited to dbt blog content.

---

#### Scope (13 adapters)

| Row                    | Source                                       | Endpoint type    | Adapter stub                          | Fetch cadence |
| ---------------------- | -------------------------------------------- | ---------------- | ------------------------------------- | ------------- |
| **ToolsÂ &Â Frameworks** | AWSÂ BigÂ DataÂ Blog                            | RSS              | `rssAdapter('awsBigData')`            | 60Â min        |
|                        | OpenAIÂ OfficialÂ Blog                         | RSS              | `rssAdapter('openai')`                | 60Â min        |
|                        | MicrosoftÂ ExcelÂ &Â PowerÂ BIÂ Blog              | RSS              | `rssAdapter('m365Excel')`             | 120Â min       |
|                        | PyPI Topâ€‘Package releases (pandas, numpy, â€¦) | perâ€‘package Atom | `pypiAdapter()`                       | 180Â min       |
| **ResearchÂ Updates**   | GoogleÂ AIÂ ResearchÂ Blog                      | Web Scrape       | `rssAdapter('googleAI')`              | 60Â min        |
|                        | HuggingÂ Face ModelÂ Releases                  | JSONÂ API         | `huggingfaceAdapter()`                | 30Â min        |
|                        | arXiv (cs.AI, cs.LG, cs.CL, stat.ML)         | RSS              | `arxivAdapter(['cs.AI', â€¦])`          | 1440Â min      |
|                        | MITÂ TechnologyÂ ReviewÂ â€“ *TheÂ Download*       | RSS              | `rssAdapter('mitTR')`                 | 720Â min       |
|                        | NeurIPS Proceedings (OpenReview)             | RSS/JSON         | `neuripsAdapter()`                    | 1440Â min      |
| **IndustryÂ News**      | TLDR.tech                                    | RSS (Substack)   | `rssAdapter('tldr')`                  | 720Â min       |
|                        | TechCrunch                                   | RSS              | *exists* (`rssAdapter('techcrunch')`) | 30Â min        |
|                        | HBRÂ Technology                               | RSS              | `rssAdapter('hbrTech')`               | 1440Â min      |
|                        | insideAIÂ News                                | RSS              | `rssAdapter('insideAI')`              | 60Â min        |

---

#### Definition of Done

- **Source rows** inserted into `sources` table with accurate `fetch_freq_min`.
- **13 new adapter modules** exporting `fetchAndParse(): ParsedItem[]`.
- **Unit tests** (Jest) for each adapter using fixture payloads (happy pathÂ + 1 edgeâ€‘case).
- **dbt schema tests** green (no NULL `stories.published_at`, vector present, etc.).
- **Grafana dashboard** panels autoâ€‘generated for each adapter (last success, errorÂ %).
- **p95 ETL latency** for WaveÂ 1 feeds <Â 10Â min.
- **Supabase row count** checked postâ€‘backfill (<Â 8Â k rows, staying within 100Â k cap).

---

#### Tech Notes

- RSS adapters reuse `rssParser.ts` util (xml2jsÂ â†’ DTO).
- `pypiAdapter()` loops through `TOP_PACKAGES` env var array; deâ€‘dupes by `externalId = '${pkg}@${version}'`.
- arXiv: build categoryâ€‘parametrised URL, strip LaTeX from `<summary>`.
- NeurIPS: consume OpenReview JSON, map `published_at` â†’ `first_decision_date`.
- **All adapters** strip zeroâ€‘width chars & convert HTMLâ†’Markdown via `turndown`.
- Batch embed with `textâ€‘embeddingâ€‘3â€‘small`; hashâ€‘gate unchanged bodies.

---

#### Impact

Populates each UI row withÂ â‰ˆ400â€“800 fresh stories, unlocking endâ€‘toâ€‘end UX tests and the relevanceâ€‘feedback loop before GA.

---

#### Reviewer Checklist

- Coding style & lint pass (`pnpm lint`).
- Unit tests cover failure modes (404, malformed XML).
- Manual run `pnpm run ingest --source=openai` ingests â‰¥Â 1Â item, visible in dashboard.
- Grafana alert thresholds set (errorÂ %Â >Â 5Â %, latencyÂ >Â 5Â min).

---

#### Dependencies

- \#42 â€œSupabase vector index tuningâ€ (merged)
- \#55 â€œGrafana datasource for Logflare logsâ€ (in review)

---

### 2 Â· Implementation Plan (ğŸ‘‹Â Cursorâ€‘first workflow)

| Phase                      | Cursor instruction                                                                                                           | CLI / Code tasks                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |
| **0Â Prep**                 | â€œGenerate a `wave1â€‘ingestion` branch from `main`.â€                                                                           | `git checkout -b wave1-ingestion`                   |
| **1Â SourceÂ Inserts**       | â€œCreate a SQL migration inserting 13 rows into `sources` with (name, type, endpoint\_url, fetch\_freq\_min, row\_category).â€ | `supabase migrate new add_wave1_sources`Â â†’ edit SQL |
| **2Â AdapterÂ Stubs**        | â€œScaffold TypeScript modules in `packages/adapters/` for each feed, exporting `fetchAndParse()`.â€                            | Cursor autoâ€‘creates 13 files                        |
| **3Â ParsingÂ Logic**        | â€œImplement `rssAdapter` generic wrapper; call with feedâ€‘specific slug.â€                                                      | Add slugâ†’sourceId util                              |
| **4Â PyPI Adapter**         | â€œLoop over `PYPI_TOP_PACKAGES` env var â†’ fetch `https://pypi.org/p/<pkg>/json` â†’ map releases.â€                              | Cache lastâ€‘seen version in KV                       |
| **5Â HF / arXiv / NeurIPS** | â€œUse `axios` to hit APIs; map JSONâ†’DTO; sanitize abstracts.â€                                                                 | Add `removeLatex.ts` helper                         |
| **6Â Tests**                | â€œGenerate Jest skeletons per adapter with fixture XML/JSON in `tests/fixtures/`.â€                                            | Add edgeâ€‘case fixture                               |
| **7Â CronÂ Wireâ€‘up**         | â€œUpdate `ingestCron.ts` switchâ€‘case with new slugs.â€                                                                         | Keep concurrencyÂ â‰¤Â 4                                |
| **8Â Observability**        | â€œExtend `metrics.ts` to emit `adapter_latency_ms` & `adapter_error`.â€                                                        | Grafana regex panels                                |
| **9Â DryÂ Run**              | â€œRun `pnpm ts-node src/cli/ingest --source=all --dry-run` and show summary.â€                                                 | Validate DTO & row diff                             |
| **10Â Backfill**            | â€œDisable `DRY_RUN`, execute ingestion once, check feed UI.â€                                                                  | Ensure vector count <Â 100Â k                         |
| **11Â PRÂ &Â Review**         | â€œOpen PR titled **feat: Wave 1 adapters**; autoâ€‘generate changelog section.â€                                                 | Assign reviewers                                    |
| **12Â Rollout**             | â€œMerge â†’ GitHubÂ Actions deploy â†’ Vercel staging â†’ promote to prod after 24Â h green metrics.â€                                 | Monitor alerts                                      |

> **Cursor tip:** prefix each instruction with `@cursor` so Cursor queues the task automatically:
>
> ```ts
> // @cursor TASK: Implement rssAdapter('openai')
> ```

With this issue and plan in place, WaveÂ 1 ingestion can be delivered in a single sprint, bringing real multiâ€‘source content to beta testers.

